{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 Sparse matrix 일 때 cosine distance 를 이용하면 대부분의 거리가 0.9 ~ 1.0 에 가깝습니다. 그렇기 때문에 bag of words model 을 이용하는 term frequency matrix 에서는 k-means++ 가 큰 의미가 없습니다. \n",
    "\n",
    "k-means++ 은 distance distribution 이 한쪽에 치우치지 않았을 때 잘 작동합니다. Similar cut initializer 는 term frequency matrix 와 같은 sparse vector 에서 효율적으로 initial points 를 선택하기 위한 방법입니다. 더 자세한 설명은 아래의 블로그를 참고해주세요.\n",
    "\n",
    "https://lovit.github.io/nlp/machine%20learning/2018/03/19/kmeans_initializer/\n",
    "\n",
    "실험에 이용하는 데이터는 https://github.com/lovit/textmining_dataset/ 에서 다운받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30091, 9774)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lovit_textmining_dataset.navernews_10days import get_bow\n",
    "\n",
    "x, idx_to_vocab, vocab_to_idx = get_bow(date='2016-10-20', tokenize='noun')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx_to_vocab 은 9.774 개의 단어들의 idx 에 해당하는 단어가 저장되어 있습니다. 이는 cluster labeling 에 이용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아이스크림', '아이엠', '아이오아이', '아이콘', '아이템']\n"
     ]
    }
   ],
   "source": [
    "print(idx_to_vocab[5535:5540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import soyclustering\n",
    "\n",
    "print(soyclustering.__version__)\n",
    "\n",
    "n_clusters = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time comparison\n",
    "\n",
    "### Initializer: similar cut vs. k-means++\n",
    "\n",
    "k-means++ 을 이용할 경우 (30091, 9774) 데이터에 대하여 initialization 에 9.462 초를 이용합니다.\n",
    "\n",
    "similar cut 은 비슷한 점들을 initial points 로 선택하지 않으면서도 0.043 초만에 initialization 이 가능합니다. distance distribution 이 0.9 ~ 1.0 에 치우친 경우에는 k-means++ 은 잘 작동하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization_time=9.648999 sec, sparsity=0.00844\n",
      "n_iter=1, changed=29952, inertia=16427.832, iter_time=1.990 sec, sparsity=0.164\n",
      "n_iter=2, changed=5975, inertia=12413.602, iter_time=1.922 sec, sparsity=0.152\n",
      "n_iter=3, changed=2192, inertia=11976.571, iter_time=1.924 sec, sparsity=0.148\n",
      "n_iter=4, changed=1128, inertia=11838.584, iter_time=1.942 sec, sparsity=0.147\n",
      "n_iter=5, changed=701, inertia=11764.806, iter_time=1.913 sec, sparsity=0.146\n",
      "n_iter=6, changed=390, inertia=11726.887, iter_time=1.914 sec, sparsity=0.145\n",
      "n_iter=7, changed=299, inertia=11710.406, iter_time=1.899 sec, sparsity=0.145\n",
      "n_iter=8, changed=198, inertia=11700.876, iter_time=1.913 sec, sparsity=0.145\n",
      "n_iter=9, changed=159, inertia=11694.908, iter_time=1.907 sec, sparsity=0.145\n",
      "n_iter=10, changed=139, inertia=11689.538, iter_time=1.914 sec, sparsity=0.145\n",
      "process time = 29.074 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from soyclustering import SphericalKMeans\n",
    "\n",
    "kmeans = SphericalKMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    init='k-means++',\n",
    "    sparsity=None,\n",
    "    max_iter=10,\n",
    "    tol=0.0001,\n",
    "    verbose = True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "t = time.time()\n",
    "labels = kmeans.fit_predict(x)\n",
    "t = time.time() - t\n",
    "\n",
    "print('process time = {} seconds'.format('%.3f' % t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization_time=0.049929 sec, sparsity=0.00707\n",
      "n_iter=1, changed=29951, inertia=16428.435, iter_time=1.945 sec, sparsity=0.161\n",
      "n_iter=2, changed=7805, inertia=12947.107, iter_time=1.916 sec, sparsity=0.149\n",
      "n_iter=3, changed=3840, inertia=12239.101, iter_time=1.896 sec, sparsity=0.145\n",
      "n_iter=4, changed=2191, inertia=11957.270, iter_time=1.927 sec, sparsity=0.142\n",
      "n_iter=5, changed=1266, inertia=11826.583, iter_time=1.883 sec, sparsity=0.141\n",
      "n_iter=6, changed=827, inertia=11762.833, iter_time=1.905 sec, sparsity=0.141\n",
      "n_iter=7, changed=596, inertia=11717.253, iter_time=1.893 sec, sparsity=0.141\n",
      "n_iter=8, changed=526, inertia=11689.117, iter_time=1.896 sec, sparsity=0.141\n",
      "n_iter=9, changed=451, inertia=11667.402, iter_time=1.906 sec, sparsity=0.14\n",
      "n_iter=10, changed=354, inertia=11647.316, iter_time=1.896 sec, sparsity=0.14\n",
      "process time = 19.223 seconds\n"
     ]
    }
   ],
   "source": [
    "from soyclustering import SphericalKMeans\n",
    "\n",
    "kmeans = SphericalKMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    init='similar_cut',\n",
    "    sparsity=None,\n",
    "    max_iter=10,\n",
    "    tol=0.0001,\n",
    "    verbose = True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "t = time.time()\n",
    "labels = kmeans.fit_predict(x)\n",
    "t = time.time() - t\n",
    "\n",
    "print('process time = {} seconds'.format('%.3f' % t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soyclustering vs. scikit-learn\n",
    "\n",
    "각 데이터와 centroids 와의 거리 계산 후, 새로운 cluster 에 데이터를 할당하는 부분이 scikit-learn 과 다르게 구현되어 있습니다. 현재 (version 0.2.0)는 scikit-learn 의 k-means 보다 약 1.9 배 정도 더 빨리 학습됩니다.\n",
    "\n",
    "scikit-learn 은 Euclidean distance 를 이용합니다. L2 normalized 된 centroids 가 아닌 L1 normalized 이기 때문에 Cosine 과 Euclidean 의 값은 차이가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# scikit-learn KMeans use only Euclidean\n",
    "from sklearn.preprocessing import normalize\n",
    "x_ = normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 21420.119\n",
      "Iteration  1, inertia 18232.433\n",
      "Iteration  2, inertia 17830.319\n",
      "Iteration  3, inertia 17662.184\n",
      "Iteration  4, inertia 17561.343\n",
      "Iteration  5, inertia 17484.342\n",
      "Iteration  6, inertia 17430.595\n",
      "Iteration  7, inertia 17390.316\n",
      "Iteration  8, inertia 17365.886\n",
      "Iteration  9, inertia 17345.277\n",
      "process time = 57.047 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_sklearn = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    init='k-means++',\n",
    "    n_init=1,\n",
    "    max_iter=10,\n",
    "    tol=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t = time.time()\n",
    "_label = kmeans_sklearn.fit_predict(x_)\n",
    "t = time.time() - t\n",
    "\n",
    "print('process time = {} seconds'.format('%.3f' % t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## cluster labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proportion keywords 를 이용하면 cluster centroids 와 vocabulary index 를 이용하여 각 클러스터 별 cluster label 을 찾을 수 있습니다.\n",
    "\n",
    "각 cluster 별로 weight 가 높은 candidates_topk 개의 후보 중에서 proportion keyword score 가 높은 topk 개의 단어가 cluster labels 로 선택됩니다. \n",
    "\n",
    "Proportion keywords 의 원리는 아래의 블로그에 설명되어 있습니다.\n",
    "\n",
    "https://lovit.github.io/nlp/machine%20learning/2018/03/21/kmeans_cluster_labeling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunjoongkim/git/clustering4docs/soyclustering/_keyword.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  def l1_normalize(x): return x/x.sum()\n",
      "/Users/hyunjoongkim/git/clustering4docs/soyclustering/_keyword.py:67: RuntimeWarning: invalid value encountered in greater\n",
      "  indices = np.where(p_prop > 0)[0]\n"
     ]
    }
   ],
   "source": [
    "from soyclustering import proportion_keywords\n",
    "\n",
    "keywords = proportion_keywords(\n",
    "    kmeans.cluster_centers_,\n",
    "    labels,\n",
    "    index2word=idx_to_vocab,\n",
    "    topk=30,\n",
    "    candidates_topk=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keywords 는 list of list of tuple 입니다. Tuple 은 (단어, 키워드 점수)로 이뤄져 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('빅브레인', 0.9998356991641689),\n",
       " ('너무너무너무', 0.999636565607772),\n",
       " ('신용재', 0.9996209421673745),\n",
       " ('오블리스', 0.9994778748084965),\n",
       " ('갓세븐', 0.9992970603778885),\n",
       " ('다비치', 0.9991180784713255),\n",
       " ('엠카운트다운', 0.9985666150928039),\n",
       " ('아이오아이', 0.9982645820718874),\n",
       " ('세븐', 0.996996851052826),\n",
       " ('박진영', 0.9967750269776107),\n",
       " ('방탄소년단', 0.9966473687693944),\n",
       " ('트로피', 0.996464966998091),\n",
       " ('완전체', 0.996227525576321),\n",
       " ('고마워', 0.995881757255629),\n",
       " ('산들', 0.9956056841004022),\n",
       " ('잠깐', 0.9955334197813145),\n",
       " ('중독성', 0.9949229577434185),\n",
       " ('펜타곤', 0.9946393121986635),\n",
       " ('정국', 0.9936714705659159),\n",
       " ('열창', 0.9934191181343699),\n",
       " ('그대', 0.9930229656843981),\n",
       " ('상큼', 0.9906486052581086),\n",
       " ('엠넷', 0.9896207484574001),\n",
       " ('타이틀곡', 0.9894943427370902),\n",
       " ('코드', 0.9890875408599619),\n",
       " ('챔피언', 0.9883417239438613),\n",
       " ('보컬', 0.9882745238500189),\n",
       " ('곡으로', 0.987120501433232),\n",
       " ('엑스', 0.9864101743091659),\n",
       " ('1위', 0.9845189730169617)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[233]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 단어가 키워드에 포함된 cluster indices 를 저장하고, 해당 군집의 키워드를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster#233 : 빅브레인 너무너무너무 신용재 오블리스 갓세븐 다비치 엠카운트다운 아이오아이 세븐 박진영 방탄소년단 트로피 완전체 고마워 산들 잠깐 중독성 펜타곤 정국 열창 그대 상큼 엠넷 타이틀곡 코드 챔피언 보컬 곡으로 엑스 1위\n",
      "cluster#298 : 다이아 에브리원 마법 고기 기희현 예능감 음악방송 한우 회식 댄스 대결 완전체 다리 아르바이트 3인 아이오아이 걸고 안무 플레이 6년 혼자 미스 출근 활동 타이틀곡 승리 활발 태양 아이돌 멤버들\n"
     ]
    }
   ],
   "source": [
    "cluster_indices = []\n",
    "for cluster_idx, keyword in enumerate(keywords):\n",
    "    keyword = ' '.join([w for w,_ in keyword])\n",
    "    if '아이오아이' in keyword:\n",
    "        print('cluster#{} : {}'.format(cluster_idx, keyword))\n",
    "        cluster_indices.append(cluster_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 단어를 stopwords 에 추가하면 키워드를 추출할 때 해당 단어를 제외하고 키워드를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = proportion_keywords(\n",
    "    kmeans.cluster_centers_,\n",
    "    labels,\n",
    "    index2word=idx_to_vocab,\n",
    "    topk=30,\n",
    "    candidates_topk=100,\n",
    "    stopwords = {'아이오아이'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster#233 : 빅브레인 너무너무너무 신용재 오블리스 갓세븐 다비치 엠카운트다운 세븐 박진영 방탄소년단 트로피 완전체 고마워 산들 잠깐 중독성 펜타곤 정국 열창 그대 상큼 엠넷 타이틀곡 코드 챔피언 보컬 곡으로 엑스 1위 눈물\n",
      "cluster#298 : 다이아 에브리원 마법 고기 기희현 예능감 음악방송 한우 회식 댄스 대결 완전체 다리 아르바이트 3인 걸고 안무 플레이 6년 혼자 미스 출근 활동 타이틀곡 승리 활발 태양 아이돌 멤버들 먹고\n"
     ]
    }
   ],
   "source": [
    "for cluster_idx in cluster_indices:\n",
    "    keyword = keywords[cluster_idx]\n",
    "    keyword = ' '.join([w for w,_ in keyword])\n",
    "    print('cluster#{} : {}'.format(cluster_idx, keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
